{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "358e8f47",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:26.102427Z",
     "iopub.status.busy": "2025-05-13T17:25:26.102143Z",
     "iopub.status.idle": "2025-05-13T17:25:39.042523Z",
     "shell.execute_reply": "2025-05-13T17:25:39.041659Z"
    },
    "papermill": {
     "duration": 12.945616,
     "end_time": "2025-05-13T17:25:39.044051",
     "exception": false,
     "start_time": "2025-05-13T17:25:26.098435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\r\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\r\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\r\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\r\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, Subset\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from transformers.feature_extraction_utils import BatchFeature\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "!pip install python-Levenshtein\n",
    "import Levenshtein\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950eafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.050859Z",
     "iopub.status.busy": "2025-05-13T17:25:39.050217Z",
     "iopub.status.idle": "2025-05-13T17:25:39.264213Z",
     "shell.execute_reply": "2025-05-13T17:25:39.263587Z"
    },
    "papermill": {
     "duration": 0.218871,
     "end_time": "2025-05-13T17:25:39.265798",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.046927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/mlpr-data/torgo_vectors_transcripts.csv')\n",
    "df['FeaturePath'] = df['FeaturePath'].str.replace(\"E:\\\\MLPR Data\\\\Features\\\\\", \"/kaggle/input/mlpr-data/Features/Features/\")\n",
    "\n",
    "# mask to filter out entries with 'input' and 'jpg'\n",
    "mask1 = ~(df['transcipt'].str.contains('input', case=False, na=False) & \n",
    "         df['transcipt'].str.contains('jpg', case=False, na=False))\n",
    "\n",
    "# mask to filter out entries with 'say' and 'repeatedly'\n",
    "mask2 = ~(df['transcipt'].str.contains('say', case=False, na=False) & \n",
    "         df['transcipt'].str.contains('repeatedly', case=False, na=False))\n",
    "\n",
    "mask = mask1 & mask2\n",
    "\n",
    "df = df[mask]\n",
    "speakers = df[\"Speaker\"].unique() \n",
    "df.to_csv('mlpr-torgo-kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26b228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.272036Z",
     "iopub.status.busy": "2025-05-13T17:25:39.271769Z",
     "iopub.status.idle": "2025-05-13T17:25:39.278475Z",
     "shell.execute_reply": "2025-05-13T17:25:39.277734Z"
    },
    "papermill": {
     "duration": 0.011097,
     "end_time": "2025-05-13T17:25:39.279599",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.268502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TorgoASRDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        feature_path = row[\"FeaturePath\"]\n",
    "        transcript = row[\"transcipt\"]\n",
    "        speaker = row[\"Speaker\"]\n",
    "    \n",
    "        try:\n",
    "            features = torch.load(feature_path, map_location='cpu')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load feature from '{feature_path}': {e}\")\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            input_values = features.get(\"input_values\")\n",
    "            if input_values is None:\n",
    "                raise ValueError(f\"'input_values' key not found in features loaded from {feature_path}\")\n",
    "        elif hasattr(features, \"input_values\"):\n",
    "            input_values = features.input_values\n",
    "        else:\n",
    "            input_values = features\n",
    "    \n",
    "        if not isinstance(input_values, torch.Tensor):\n",
    "            input_values = torch.tensor(input_values)\n",
    "    \n",
    "        if input_values.dim() == 3:\n",
    "            input_values = input_values.squeeze(0)  \n",
    "    \n",
    "        seq_length = input_values.size(0)\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"seq_length\": seq_length,\n",
    "            \"transcript\": transcript,\n",
    "            \"speaker\": speaker\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a73943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.284954Z",
     "iopub.status.busy": "2025-05-13T17:25:39.284740Z",
     "iopub.status.idle": "2025-05-13T17:25:39.289816Z",
     "shell.execute_reply": "2025-05-13T17:25:39.289263Z"
    },
    "papermill": {
     "duration": 0.008956,
     "end_time": "2025-05-13T17:25:39.290837",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.281881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_values_list = []\n",
    "    seq_lengths = []\n",
    "    transcripts = []\n",
    "    speakers = []\n",
    "    \n",
    "    for sample in batch:\n",
    "        \n",
    "        x = sample[\"input_values\"]\n",
    "        sample_seq_length = x.size(0)\n",
    "        \n",
    "        input_values_list.append(x)\n",
    "        seq_lengths.append(sample_seq_length)\n",
    "        transcripts.append(sample[\"transcript\"])\n",
    "        speakers.append(sample[\"speaker\"])\n",
    "    \n",
    "\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence(input_values_list, batch_first=True, padding_value=0)\n",
    "    \n",
    "    \n",
    "    padded_inputs = padded_inputs.contiguous()\n",
    "    \n",
    "    return {\n",
    "        \"input_values\": padded_inputs, \n",
    "        \"seq_lengths\": torch.tensor(seq_lengths),\n",
    "        \"transcripts\": transcripts,\n",
    "        \"speakers\": speakers\n",
    "    }\n",
    "\n",
    "\n",
    "def transcript_to_indices(transcript, char_to_idx):\n",
    "    return [char_to_idx[char] for char in transcript if char in char_to_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.296350Z",
     "iopub.status.busy": "2025-05-13T17:25:39.296109Z",
     "iopub.status.idle": "2025-05-13T17:25:39.308780Z",
     "shell.execute_reply": "2025-05-13T17:25:39.308213Z"
    },
    "papermill": {
     "duration": 0.016769,
     "end_time": "2025-05-13T17:25:39.309798",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.293029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = torch.sqrt(torch.tensor(hidden_dim, dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, hidden_dim]\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "        \n",
    "        q = self.query(x) \n",
    "        k = self.key(x)   \n",
    "        v = self.value(x)  \n",
    "        \n",
    "        # attention scores (scaled dot-product attention)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale  \n",
    "        \n",
    "        # softmax to get attention weights\n",
    "        attn_weights = torch.softmax(scores, dim=-1) \n",
    "        \n",
    "        context = torch.matmul(attn_weights, v) \n",
    "        \n",
    "        # Combine with residual connection\n",
    "        output = context + x  \n",
    "        \n",
    "        return output\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, vocab_size, num_layers=3, dropout_rate=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=hidden_dim if i==0 else hidden_dim*2,\n",
    "                hidden_size=hidden_dim,\n",
    "                batch_first=True,\n",
    "                bidirectional=True\n",
    "            ) for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout_rate) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim*2) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.attention = AttentionLayer(hidden_dim*2)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, vocab_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3 and x.size(2) == 1:  \n",
    "            x = x.squeeze(2)\n",
    "            x = x.unsqueeze(2)\n",
    "            \n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        \n",
    "\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        residual = None\n",
    "        for i, (lstm, dropout, layer_norm) in enumerate(zip(self.lstm_layers, self.dropouts, self.layer_norms)):\n",
    "            lstm_out, _ = lstm(x)\n",
    "            lstm_out = dropout(lstm_out)\n",
    "            \n",
    "            if residual is not None and lstm_out.size() == residual.size():\n",
    "                lstm_out = lstm_out + residual\n",
    "                \n",
    "            lstm_out = layer_norm(lstm_out)\n",
    "            \n",
    "            # attention after the final LSTM layer\n",
    "            if i == len(self.lstm_layers) - 1:\n",
    "                lstm_out = self.attention(lstm_out)\n",
    "                \n",
    "            residual = lstm_out\n",
    "            x = lstm_out\n",
    "        \n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        logits = logits.transpose(0, 1)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def decode(self, x, seq_lengths):\n",
    "        \"\"\"Generate text predictions for the input batch\"\"\"\n",
    "        logits = self.forward(x) \n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(logits, dim=2)  \n",
    "        predictions = predictions.transpose(0, 1)  \n",
    "        \n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16f39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.315071Z",
     "iopub.status.busy": "2025-05-13T17:25:39.314871Z",
     "iopub.status.idle": "2025-05-13T17:25:39.336617Z",
     "shell.execute_reply": "2025-05-13T17:25:39.336029Z"
    },
    "papermill": {
     "duration": 0.025749,
     "end_time": "2025-05-13T17:25:39.337753",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.312004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_cer(reference, prediction):\n",
    "    distance = Levenshtein.distance(reference, prediction)\n",
    "    return distance / max(len(reference), 1)\n",
    "\n",
    "def calculate_wer(reference, prediction):\n",
    "    ref_words = reference.split()\n",
    "    pred_words = prediction.split()\n",
    "    distance = Levenshtein.distance(ref_words, pred_words)\n",
    "    return distance / max(len(ref_words), 1)\n",
    "\n",
    "def trainModel(model, train_loader, val_loader, char_to_idx, num_epochs=10, learning_rate=1e-4, patience=3, min_delta=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            inputs = batch[\"input_values\"].to(device)\n",
    "            input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "            \n",
    "            targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                            for t in batch[\"transcripts\"]]\n",
    "            targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "            \n",
    "            targets = torch.cat(targets_list).to(device)\n",
    "            target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "            loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                inputs = batch[\"input_values\"].to(device)\n",
    "                input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "                \n",
    "                targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                                for t in batch[\"transcripts\"]]\n",
    "                targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "                targets = torch.cat(targets_list).to(device)\n",
    "                target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "                loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "                \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current learning rate: {current_lr:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epochs\")\n",
    "            \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "    \n",
    "    if best_model_state is not None and epochs_without_improvement < patience:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    print(\"Training complete.\")\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "def evaluateModel(model, test_loader, char_to_idx, idx_to_char, output_csv=\"evaluation_results.csv\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    test_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_transcripts = []\n",
    "    all_speakers = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
    "        for batch in test_pbar:\n",
    "            inputs = batch[\"input_values\"].to(device)\n",
    "            input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "            transcripts = batch[\"transcripts\"]\n",
    "            speakers = batch[\"speakers\"]\n",
    "            \n",
    "            targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                            for t in transcripts]\n",
    "            targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "            targets = torch.cat(targets_list).to(device)\n",
    "            target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "            loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(outputs, dim=2).transpose(0, 1)  # [batch, time]\n",
    "            \n",
    "            batch_texts = []\n",
    "            for pred in predictions:\n",
    "                pred_collapsed = []\n",
    "                prev = None\n",
    "                for p in pred:\n",
    "                    if p.item() != prev:\n",
    "                        pred_collapsed.append(p.item())\n",
    "                        prev = p.item()\n",
    "                \n",
    "                text = ''.join([idx_to_char.get(p, '') for p in pred_collapsed if p > 0])\n",
    "                batch_texts.append(text)\n",
    "            \n",
    "            all_predictions.extend(batch_texts)\n",
    "            all_transcripts.extend(transcripts)\n",
    "            all_speakers.extend(speakers)\n",
    "            \n",
    "            test_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        print(f\"Final Test Loss: {avg_test_loss:.4f}\")\n",
    "        \n",
    "        # overall WER and CER\n",
    "        total_cer = 0.0\n",
    "        total_wer = 0.0\n",
    "        for ref, pred in zip(all_transcripts, all_predictions):\n",
    "            total_cer += calculate_cer(ref, pred)\n",
    "            total_wer += calculate_wer(ref, pred)\n",
    "        \n",
    "        avg_cer = total_cer / len(all_predictions)\n",
    "        avg_wer = total_wer / len(all_predictions)\n",
    "        print(f\"Overall Character Error Rate: {avg_cer:.4f}\")\n",
    "        print(f\"Overall Word Error Rate: {avg_wer:.4f}\")\n",
    "        \n",
    "        # per-speaker metrics\n",
    "        speaker_predictions = defaultdict(list)\n",
    "        speaker_references = defaultdict(list)\n",
    "        \n",
    "        for speaker, ref, pred in zip(all_speakers, all_transcripts, all_predictions):\n",
    "            speaker_predictions[speaker].append(pred)\n",
    "            speaker_references[speaker].append(ref)\n",
    "        \n",
    "        print(\"\\nPer-Speaker Metrics:\")\n",
    "        for speaker in sorted(speaker_predictions.keys()):\n",
    "            preds = speaker_predictions[speaker]\n",
    "            refs = speaker_references[speaker]\n",
    "            \n",
    "            speaker_cer = sum(calculate_cer(r, p) for r, p in zip(refs, preds)) / len(preds)\n",
    "            speaker_wer = sum(calculate_wer(r, p) for r, p in zip(refs, preds)) / len(preds)\n",
    "            \n",
    "            print(f\"Speaker {speaker} (samples: {len(preds)})\")\n",
    "            print(f\"  - Character Error Rate: {speaker_cer:.4f}\")\n",
    "            print(f\"  - Word Error Rate: {speaker_wer:.4f}\")\n",
    "        \n",
    "        for i in range(min(15, len(all_predictions))):\n",
    "            print(f\"Example {i+1} (Speaker: {all_speakers[i]}):\\nReference: '{all_transcripts[i]}'\\nPrediction: '{all_predictions[i]}'\")\n",
    "        \n",
    "        # Save results to CSV file\n",
    "        results_df = pd.DataFrame({\n",
    "            'speaker': all_speakers,\n",
    "            'reference': all_transcripts,\n",
    "            'prediction': all_predictions,\n",
    "            'cer': [calculate_cer(ref, pred) for ref, pred in zip(all_transcripts, all_predictions)],\n",
    "            'wer': [calculate_wer(ref, pred) for ref, pred in zip(all_transcripts, all_predictions)]\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nEvaluation results saved to {output_csv}\")\n",
    "        \n",
    "        return avg_test_loss, all_predictions, all_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1eb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:25:39.343370Z",
     "iopub.status.busy": "2025-05-13T17:25:39.342826Z",
     "iopub.status.idle": "2025-05-13T17:39:32.687935Z",
     "shell.execute_reply": "2025-05-13T17:39:32.686636Z"
    },
    "papermill": {
     "duration": 833.349288,
     "end_time": "2025-05-13T17:39:32.689393",
     "exception": false,
     "start_time": "2025-05-13T17:25:39.340105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|██████████| 81/81 [01:29<00:00,  1.11s/it, loss=1.8415]\n",
      "Epoch 1/30 [Val]: 100%|██████████| 27/27 [00:23<00:00,  1.13it/s, val_loss=1.2794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Training Loss: 1.3898, Validation Loss: 1.3069\n",
      "Current learning rate: 0.000500\n",
      "New best validation loss: 1.3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 81/81 [00:46<00:00,  1.75it/s, loss=1.0414]\n",
      "Epoch 2/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.82it/s, val_loss=1.2053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30] Training Loss: 1.2135, Validation Loss: 1.2833\n",
      "Current learning rate: 0.000500\n",
      "New best validation loss: 1.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=1.4629]\n",
      "Epoch 3/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.78it/s, val_loss=1.1633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] Training Loss: 1.1374, Validation Loss: 1.1832\n",
      "Current learning rate: 0.000500\n",
      "New best validation loss: 1.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.71it/s, loss=1.0847]\n",
      "Epoch 4/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.80it/s, val_loss=1.1470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30] Training Loss: 1.0870, Validation Loss: 1.2149\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 81/81 [00:46<00:00,  1.74it/s, loss=0.7069]\n",
      "Epoch 5/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.80it/s, val_loss=1.1511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] Training Loss: 1.0277, Validation Loss: 1.2081\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=0.8190]\n",
      "Epoch 6/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.81it/s, val_loss=1.0924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30] Training Loss: 1.0000, Validation Loss: 1.1791\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=0.7155]\n",
      "Epoch 7/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.86it/s, val_loss=1.1175]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] Training Loss: 0.9585, Validation Loss: 1.1811\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=1.1346]\n",
      "Epoch 8/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.83it/s, val_loss=1.0692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/30] Training Loss: 0.9233, Validation Loss: 1.1411\n",
      "Current learning rate: 0.000500\n",
      "New best validation loss: 1.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=1.1313]\n",
      "Epoch 9/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.86it/s, val_loss=1.1293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] Training Loss: 0.8946, Validation Loss: 1.1777\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|██████████| 81/81 [00:46<00:00,  1.73it/s, loss=0.8709]\n",
      "Epoch 10/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.83it/s, val_loss=1.0920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/30] Training Loss: 0.8459, Validation Loss: 1.1895\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 81/81 [00:46<00:00,  1.72it/s, loss=0.9172]\n",
      "Epoch 11/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.81it/s, val_loss=1.1326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] Training Loss: 0.8244, Validation Loss: 1.1797\n",
      "Current learning rate: 0.000250\n",
      "No improvement for 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 81/81 [00:46<00:00,  1.74it/s, loss=0.7721]\n",
      "Epoch 12/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.86it/s, val_loss=1.0749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/30] Training Loss: 0.7404, Validation Loss: 1.1735\n",
      "Current learning rate: 0.000250\n",
      "No improvement for 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 81/81 [00:47<00:00,  1.72it/s, loss=0.7569]\n",
      "Epoch 13/30 [Val]: 100%|██████████| 27/27 [00:09<00:00,  2.87it/s, val_loss=1.0251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] Training Loss: 0.7003, Validation Loss: 1.1316\n",
      "Current learning rate: 0.000250\n",
      "No improvement for 5 epochs\n",
      "Early stopping after 13 epochs\n",
      "Training complete.\n",
      "Best validation loss: 1.1411\n",
      "Evaluating best model on test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 27/27 [00:36<00:00,  1.35s/it, loss=1.0196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 1.0385\n",
      "Overall Character Error Rate: 0.2662\n",
      "Overall Word Error Rate: 0.4875\n",
      "\n",
      "Per-Speaker Metrics:\n",
      "Speaker F01 (samples: 22)\n",
      "  - Character Error Rate: 0.6014\n",
      "  - Word Error Rate: 0.9331\n",
      "Speaker F03 (samples: 128)\n",
      "  - Character Error Rate: 0.4322\n",
      "  - Word Error Rate: 0.7225\n",
      "Speaker F04 (samples: 89)\n",
      "  - Character Error Rate: 0.1840\n",
      "  - Word Error Rate: 0.3938\n",
      "Speaker FC01 (samples: 42)\n",
      "  - Character Error Rate: 0.3069\n",
      "  - Word Error Rate: 0.5347\n",
      "Speaker FC02 (samples: 244)\n",
      "  - Character Error Rate: 0.1776\n",
      "  - Word Error Rate: 0.4225\n",
      "Speaker FC03 (samples: 192)\n",
      "  - Character Error Rate: 0.2677\n",
      "  - Word Error Rate: 0.4635\n",
      "Speaker M01 (samples: 13)\n",
      "  - Character Error Rate: 0.6358\n",
      "  - Word Error Rate: 1.0000\n",
      "Speaker M02 (samples: 79)\n",
      "  - Character Error Rate: 0.6662\n",
      "  - Word Error Rate: 0.9491\n",
      "Speaker M03 (samples: 96)\n",
      "  - Character Error Rate: 0.1804\n",
      "  - Word Error Rate: 0.3495\n",
      "Speaker M04 (samples: 89)\n",
      "  - Character Error Rate: 0.6250\n",
      "  - Word Error Rate: 0.9287\n",
      "Speaker M05 (samples: 19)\n",
      "  - Character Error Rate: 0.7222\n",
      "  - Word Error Rate: 0.9912\n",
      "Speaker MC01 (samples: 203)\n",
      "  - Character Error Rate: 0.1718\n",
      "  - Word Error Rate: 0.3901\n",
      "Speaker MC02 (samples: 135)\n",
      "  - Character Error Rate: 0.2414\n",
      "  - Word Error Rate: 0.4666\n",
      "Speaker MC03 (samples: 163)\n",
      "  - Character Error Rate: 0.1096\n",
      "  - Word Error Rate: 0.2675\n",
      "Speaker MC04 (samples: 205)\n",
      "  - Character Error Rate: 0.1568\n",
      "  - Word Error Rate: 0.3248\n",
      "Example 1 (Speaker: F04):\n",
      "Reference: 'knew'\n",
      "Prediction: 'knew'\n",
      "Example 2 (Speaker: FC01):\n",
      "Reference: 'whoop'\n",
      "Prediction: 'woap'\n",
      "Example 3 (Speaker: FC03):\n",
      "Reference: 'the family requests that flowers be omitted'\n",
      "Prediction: 'the family requests that flowers be omitted'\n",
      "Example 4 (Speaker: MC02):\n",
      "Reference: 'shred'\n",
      "Prediction: 'shred'\n",
      "Example 5 (Speaker: FC03):\n",
      "Reference: 'i tell you it was wonderful'\n",
      "Prediction: 'i tell you it was wonderful'\n",
      "Example 6 (Speaker: MC04):\n",
      "Reference: 'bubble'\n",
      "Prediction: 'bube'\n",
      "Example 7 (Speaker: FC02):\n",
      "Reference: 'spade'\n",
      "Prediction: 'fade'\n",
      "Example 8 (Speaker: MC02):\n",
      "Reference: 'if you are losing water replace it immediately'\n",
      "Prediction: 'if you are losing water replace it immediately'\n",
      "Example 9 (Speaker: M03):\n",
      "Reference: 'slip'\n",
      "Prediction: 'slip'\n",
      "Example 10 (Speaker: F03):\n",
      "Reference: 'ride'\n",
      "Prediction: 'side'\n",
      "Example 11 (Speaker: FC02):\n",
      "Reference: 'bow as in bow and arrow'\n",
      "Prediction: 'bow'\n",
      "Example 12 (Speaker: F04):\n",
      "Reference: 'loyal'\n",
      "Prediction: 'loyal'\n",
      "Example 13 (Speaker: FC03):\n",
      "Reference: 'the hotel owner shrugged'\n",
      "Prediction: 'the hotel owner shrugged'\n",
      "Example 14 (Speaker: F04):\n",
      "Reference: 'sweet'\n",
      "Prediction: 'sweet'\n",
      "Example 15 (Speaker: MC01):\n",
      "Reference: 'the prospect of cutting back spending is an unpleasant one for any governor'\n",
      "Prediction: 'the prospect of cutting back spending is an unpleasant one for any governor'\n",
      "\n",
      "Evaluation results saved to evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab = \"abcdefghijklmnopqrstuvwxyz \" #output chars\n",
    "char_to_idx = {char: i+1 for i, char in enumerate(vocab)}\n",
    "idx_to_char = {i+1: char for i, char in enumerate(vocab)}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "\n",
    "csv_file = \"/kaggle/working/mlpr-torgo-kaggle.csv\"\n",
    "full_dataset = TorgoASRDataset(csv_file)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(full_dataset)), \n",
    "    test_size=0.2, \n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_idx, \n",
    "    test_size=0.25,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset, val_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "input_dim = 1024\n",
    "hidden_dim = 256\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "model = Model(input_dim=input_dim, hidden_dim=hidden_dim, vocab_size=vocab_size, num_layers=3, dropout_rate=0.3)\n",
    "ckpt = torch.load(\"/kaggle/input/libri-pretrained-model/libri_asr_model.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "\n",
    "best_val_loss = trainModel(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    char_to_idx, \n",
    "    num_epochs=30, \n",
    "    learning_rate=5e-4, \n",
    "    patience=5, \n",
    "    min_delta=0.01\n",
    ")\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"Evaluating best model on test set:\")\n",
    "test_loss, predictions, references = evaluateModel(model, test_loader, char_to_idx, idx_to_char)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7146065,
     "sourceId": 11797899,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7407272,
     "sourceId": 11799494,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 853.573786,
   "end_time": "2025-05-13T17:39:35.637497",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T17:25:22.063711",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
