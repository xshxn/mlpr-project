{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba5e1ac",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-13T14:30:39.817468Z",
     "iopub.status.busy": "2025-05-13T14:30:39.816940Z",
     "iopub.status.idle": "2025-05-13T14:31:13.508326Z",
     "shell.execute_reply": "2025-05-13T14:31:13.507340Z"
    },
    "papermill": {
     "duration": 33.696747,
     "end_time": "2025-05-13T14:31:13.509749",
     "exception": false,
     "start_time": "2025-05-13T14:30:39.813002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 14:30:57.039566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747146657.235632      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747146657.296080      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\r\n",
      "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\r\n",
      "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\r\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\r\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\r\n",
      "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\r\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2FeatureExtractor\n",
    "import tqdm\n",
    "import pathlib\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, Subset\n",
    "from transformers.feature_extraction_utils import BatchFeature\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "!pip install python-Levenshtein\n",
    "import Levenshtein\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ba41c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:13.517869Z",
     "iopub.status.busy": "2025-05-13T14:31:13.515999Z",
     "iopub.status.idle": "2025-05-13T14:31:15.939060Z",
     "shell.execute_reply": "2025-05-13T14:31:15.938340Z"
    },
    "papermill": {
     "duration": 2.427731,
     "end_time": "2025-05-13T14:31:15.940424",
     "exception": false,
     "start_time": "2025-05-13T14:31:13.512693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/kaggle/input/receptiondata/librispeech_manifest_with_feats.csv')\n",
    "df2 = pd.read_csv('/kaggle/input/wave2vec-features-16001-to-24000/librispeech_manifest_with_feats.csv')\n",
    "df3 = pd.read_csv('/kaggle/input/librifeatures1/librispeech_manifest_with_feats.csv')\n",
    "df4 = pd.read_csv('/kaggle/input/librifeatures-24001-32000/librispeech_manifest_with_feats.csv')\n",
    "df5 = pd.read_csv('/kaggle/input/librifeatures-32001-40000/librispeech_manifest_with_feats.csv')\n",
    "df6 = pd.read_csv('/kaggle/input/librifeatures-40001-48000/librispeech_manifest_with_feats.csv')\n",
    "\n",
    "\n",
    "df1['feature_path'] = df1['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/receptiondata\")\n",
    "df2['feature_path'] = df2['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/wave2vec-features-16001-to-24000\")\n",
    "df3['feature_path'] = df3['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/librifeatures1\")\n",
    "df4['feature_path'] = df4['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/librifeatures-24001-32000\")\n",
    "df5['feature_path'] = df5['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/librifeatures-32001-40000\")\n",
    "df6['feature_path'] = df6['feature_path'].str.replace(\"/kaggle/working\", \"/kaggle/input/librifeatures-40001-48000\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=0)\n",
    "\n",
    "mask1 = ~(df['text'].str.contains('input', case=False, na=False) & \n",
    "         df['text'].str.contains('jpg', case=False, na=False))\n",
    "\n",
    "mask2 = ~(df['text'].str.contains('say', case=False, na=False) & \n",
    "         df['text'].str.contains('repeatedly', case=False, na=False))\n",
    "\n",
    "mask = mask1 & mask2\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "def normalize_transcript(text):\n",
    "        \n",
    "    text = text.lower()\n",
    "    normalized = re.sub(r'[^a-z ]+', '', text)\n",
    "    normalized = re.sub(r'\\s+', ' ', normalized).strip()\n",
    "    return normalized\n",
    "\n",
    "df['text'] = df['text'].apply(normalize_transcript)\n",
    "df.to_csv('mlpr-libri-kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57768c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:15.946741Z",
     "iopub.status.busy": "2025-05-13T14:31:15.946479Z",
     "iopub.status.idle": "2025-05-13T14:31:15.952716Z",
     "shell.execute_reply": "2025-05-13T14:31:15.951988Z"
    },
    "papermill": {
     "duration": 0.010548,
     "end_time": "2025-05-13T14:31:15.953811",
     "exception": false,
     "start_time": "2025-05-13T14:31:15.943263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LibriASRDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        feature_path = row[\"feature_path\"]\n",
    "        transcript = row[\"text\"]\n",
    "        speaker = row[\"speaker_id\"]\n",
    "    \n",
    "        try:\n",
    "            features = torch.load(feature_path, map_location='cpu')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load feature from '{feature_path}': {e}\")\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            input_values = features.get(\"input_values\")\n",
    "            if input_values is None:\n",
    "                raise ValueError(f\"'input_values' key not found in features loaded from {feature_path}\")\n",
    "        elif hasattr(features, \"input_values\"):\n",
    "            input_values = features.input_values\n",
    "        else:\n",
    "            input_values = features\n",
    "    \n",
    "        if not isinstance(input_values, torch.Tensor):\n",
    "            input_values = torch.tensor(input_values)\n",
    "    \n",
    "        if input_values.dim() == 3:\n",
    "            input_values = input_values.squeeze(0)  # now shape is (T, hidden_size)\n",
    "    \n",
    "        seq_length = input_values.size(0)\n",
    "        \n",
    "        return {\n",
    "            \"input_values\": input_values,\n",
    "            \"seq_length\": seq_length,\n",
    "            \"transcript\": transcript,\n",
    "            \"speaker\": speaker\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af2ce2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:15.959739Z",
     "iopub.status.busy": "2025-05-13T14:31:15.959052Z",
     "iopub.status.idle": "2025-05-13T14:31:15.964327Z",
     "shell.execute_reply": "2025-05-13T14:31:15.963824Z"
    },
    "papermill": {
     "duration": 0.009196,
     "end_time": "2025-05-13T14:31:15.965382",
     "exception": false,
     "start_time": "2025-05-13T14:31:15.956186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_values_list = []\n",
    "    seq_lengths = []\n",
    "    transcripts = []\n",
    "    speakers = []\n",
    "    \n",
    "    for sample in batch:\n",
    "        \n",
    "        x = sample[\"input_values\"]\n",
    "        sample_seq_length = x.size(0)\n",
    "        \n",
    "        input_values_list.append(x)\n",
    "        seq_lengths.append(sample_seq_length)\n",
    "        transcripts.append(sample[\"transcript\"])\n",
    "        speakers.append(sample[\"speaker\"])\n",
    "    \n",
    "\n",
    "    padded_inputs = torch.nn.utils.rnn.pad_sequence(input_values_list, batch_first=True, padding_value=0)\n",
    "    \n",
    "    \n",
    "    padded_inputs = padded_inputs.contiguous()\n",
    "    \n",
    "    return {\n",
    "        \"input_values\": padded_inputs,  # Now shape: (batch, time, hidden_size)\n",
    "        \"seq_lengths\": torch.tensor(seq_lengths),\n",
    "        \"transcripts\": transcripts,\n",
    "        \"speakers\": speakers\n",
    "    }\n",
    "\n",
    "\n",
    "def transcript_to_indices(transcript, char_to_idx):\n",
    "    return [char_to_idx[char] for char in transcript if char in char_to_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6143bd4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:15.971214Z",
     "iopub.status.busy": "2025-05-13T14:31:15.970830Z",
     "iopub.status.idle": "2025-05-13T14:31:15.984073Z",
     "shell.execute_reply": "2025-05-13T14:31:15.983520Z"
    },
    "papermill": {
     "duration": 0.017151,
     "end_time": "2025-05-13T14:31:15.984975",
     "exception": false,
     "start_time": "2025-05-13T14:31:15.967824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.scale = torch.sqrt(torch.tensor(hidden_dim, dtype=torch.float32))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, hidden_dim]\n",
    "        batch_size, seq_len, hidden_dim = x.size()\n",
    "        \n",
    "        # Compute query, key, value projections\n",
    "        q = self.query(x)  # [batch_size, seq_len, hidden_dim]\n",
    "        k = self.key(x)    # [batch_size, seq_len, hidden_dim]\n",
    "        v = self.value(x)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # Compute attention scores (scaled dot-product attention)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale  # [batch_size, seq_len, seq_len]\n",
    "        \n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = torch.softmax(scores, dim=-1)  # [batch_size, seq_len, seq_len]\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        context = torch.matmul(attn_weights, v)  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        # Combine with residual connection\n",
    "        output = context + x  # [batch_size, seq_len, hidden_dim]\n",
    "        \n",
    "        return output\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, vocab_size, num_layers=3, dropout_rate=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=hidden_dim if i==0 else hidden_dim*2,\n",
    "                hidden_size=hidden_dim,\n",
    "                batch_first=True,\n",
    "                bidirectional=True\n",
    "            ) for i in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(dropout_rate) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim*2) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.attention = AttentionLayer(hidden_dim*2)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, vocab_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3 and x.size(2) == 1:  \n",
    "            x = x.squeeze(2)\n",
    "            x = x.unsqueeze(2)\n",
    "            \n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        \n",
    "\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        residual = None\n",
    "        for i, (lstm, dropout, layer_norm) in enumerate(zip(self.lstm_layers, self.dropouts, self.layer_norms)):\n",
    "            lstm_out, _ = lstm(x)\n",
    "            lstm_out = dropout(lstm_out)\n",
    "            \n",
    "            if residual is not None and lstm_out.size() == residual.size():\n",
    "                lstm_out = lstm_out + residual\n",
    "                \n",
    "            lstm_out = layer_norm(lstm_out)\n",
    "            \n",
    "            # Apply attention after the final LSTM layer\n",
    "            if i == len(self.lstm_layers) - 1:\n",
    "                lstm_out = self.attention(lstm_out)\n",
    "                \n",
    "            residual = lstm_out\n",
    "            x = lstm_out\n",
    "        \n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        logits = logits.transpose(0, 1)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def decode(self, x, seq_lengths):\n",
    "\n",
    "        logits = self.forward(x) \n",
    "        \n",
    "\n",
    "        predictions = torch.argmax(logits, dim=2)  \n",
    "        predictions = predictions.transpose(0, 1)  \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c441377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:15.991951Z",
     "iopub.status.busy": "2025-05-13T14:31:15.991763Z",
     "iopub.status.idle": "2025-05-13T14:31:16.014174Z",
     "shell.execute_reply": "2025-05-13T14:31:16.013657Z"
    },
    "papermill": {
     "duration": 0.027667,
     "end_time": "2025-05-13T14:31:16.015087",
     "exception": false,
     "start_time": "2025-05-13T14:31:15.987420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_cer(reference, prediction):\n",
    "    distance = Levenshtein.distance(reference, prediction)\n",
    "    return distance / max(len(reference), 1)\n",
    "\n",
    "def calculate_wer(reference, prediction):\n",
    "    ref_words = reference.split()\n",
    "    pred_words = prediction.split()\n",
    "    distance = Levenshtein.distance(ref_words, pred_words)\n",
    "    return distance / max(len(ref_words), 1)\n",
    "\n",
    "def trainModel(model, train_loader, val_loader, char_to_idx, num_epochs=10, learning_rate=1e-4, patience=3, min_delta=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            inputs = batch[\"input_values\"].to(device)\n",
    "            input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "            \n",
    "            targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                            for t in batch[\"transcripts\"]]\n",
    "            targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "            \n",
    "            targets = torch.cat(targets_list).to(device)\n",
    "            target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "            loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_pbar = tqdm.tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                inputs = batch[\"input_values\"].to(device)\n",
    "                input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "                \n",
    "                targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                                for t in batch[\"transcripts\"]]\n",
    "                targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "                targets = torch.cat(targets_list).to(device)\n",
    "                target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "                loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "                val_loss += loss.item()\n",
    "                val_pbar.set_postfix({\"val_loss\": f\"{loss.item():.4f}\"})\n",
    "                \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current learning rate: {current_lr:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss - min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best validation loss: {best_val_loss:.4f}\")\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            print(f\"No improvement for {epochs_without_improvement} epochs\")\n",
    "            \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "    \n",
    "    if best_model_state is not None and epochs_without_improvement < patience:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    print(\"Training complete.\")\n",
    "    return best_val_loss\n",
    "\n",
    "\n",
    "def evaluateModel(model, test_loader, char_to_idx, idx_to_char, output_csv=\"evaluation_results.csv\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    test_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_transcripts = []\n",
    "    all_speakers = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_pbar = tqdm.tqdm(test_loader, desc=\"Evaluating\")\n",
    "        for batch in test_pbar:\n",
    "            inputs = batch[\"input_values\"].to(device)\n",
    "            input_lengths = batch[\"seq_lengths\"].to(device)\n",
    "            transcripts = batch[\"transcripts\"]\n",
    "            speakers = batch[\"speakers\"]\n",
    "            \n",
    "            targets_list = [torch.tensor(transcript_to_indices(t, char_to_idx), dtype=torch.long)\n",
    "                            for t in transcripts]\n",
    "            targets_list = [t if len(t) > 0 else torch.tensor([0], dtype=torch.long) for t in targets_list]\n",
    "            targets = torch.cat(targets_list).to(device)\n",
    "            target_lengths = torch.tensor([len(t) for t in targets_list], dtype=torch.long).to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            log_probs = torch.nn.functional.log_softmax(outputs, dim=2)\n",
    "            loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(outputs, dim=2).transpose(0, 1)  # [batch, time]\n",
    "            \n",
    "            batch_texts = []\n",
    "            for pred in predictions:\n",
    "                pred_collapsed = []\n",
    "                prev = None\n",
    "                for p in pred:\n",
    "                    if p.item() != prev:\n",
    "                        pred_collapsed.append(p.item())\n",
    "                        prev = p.item()\n",
    "                \n",
    "                text = ''.join([idx_to_char.get(p, '') for p in pred_collapsed if p > 0])\n",
    "                batch_texts.append(text)\n",
    "            \n",
    "            all_predictions.extend(batch_texts)\n",
    "            all_transcripts.extend(transcripts)\n",
    "            all_speakers.extend(speakers)\n",
    "            \n",
    "            test_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            \n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "        print(f\"Final Test Loss: {avg_test_loss:.4f}\")\n",
    "        \n",
    "        # Calculate overall WER and CER\n",
    "        total_cer = 0.0\n",
    "        total_wer = 0.0\n",
    "        for ref, pred in zip(all_transcripts, all_predictions):\n",
    "            total_cer += calculate_cer(ref, pred)\n",
    "            total_wer += calculate_wer(ref, pred)\n",
    "        \n",
    "        avg_cer = total_cer / len(all_predictions)\n",
    "        avg_wer = total_wer / len(all_predictions)\n",
    "        print(f\"Overall Character Error Rate: {avg_cer:.4f}\")\n",
    "        print(f\"Overall Word Error Rate: {avg_wer:.4f}\")\n",
    "        \n",
    "        # Calculate per-speaker metrics\n",
    "        speaker_predictions = defaultdict(list)\n",
    "        speaker_references = defaultdict(list)\n",
    "        \n",
    "        for speaker, ref, pred in zip(all_speakers, all_transcripts, all_predictions):\n",
    "            speaker_predictions[speaker].append(pred)\n",
    "            speaker_references[speaker].append(ref)\n",
    "        \n",
    "        print(\"\\nPer-Speaker Metrics:\")\n",
    "        for speaker in sorted(speaker_predictions.keys()):\n",
    "            preds = speaker_predictions[speaker]\n",
    "            refs = speaker_references[speaker]\n",
    "            \n",
    "            speaker_cer = sum(calculate_cer(r, p) for r, p in zip(refs, preds)) / len(preds)\n",
    "            speaker_wer = sum(calculate_wer(r, p) for r, p in zip(refs, preds)) / len(preds)\n",
    "            \n",
    "            print(f\"Speaker {speaker} (samples: {len(preds)})\")\n",
    "            print(f\"  - Character Error Rate: {speaker_cer:.4f}\")\n",
    "            print(f\"  - Word Error Rate: {speaker_wer:.4f}\")\n",
    "        \n",
    "        for i in range(min(15, len(all_predictions))):\n",
    "            print(f\"Example {i+1} (Speaker: {all_speakers[i]}):\\nReference: '{all_transcripts[i]}'\\nPrediction: '{all_predictions[i]}'\")\n",
    "        \n",
    "        # Save results to CSV file\n",
    "        results_df = pd.DataFrame({\n",
    "            'speaker': all_speakers,\n",
    "            'reference': all_transcripts,\n",
    "            'prediction': all_predictions,\n",
    "            'cer': [calculate_cer(ref, pred) for ref, pred in zip(all_transcripts, all_predictions)],\n",
    "            'wer': [calculate_wer(ref, pred) for ref, pred in zip(all_transcripts, all_predictions)]\n",
    "        })\n",
    "        \n",
    "        results_df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nEvaluation results saved to {output_csv}\")\n",
    "        \n",
    "        return avg_test_loss, all_predictions, all_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96d6aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T14:31:16.020693Z",
     "iopub.status.busy": "2025-05-13T14:31:16.020500Z",
     "iopub.status.idle": "2025-05-13T17:07:08.632361Z",
     "shell.execute_reply": "2025-05-13T17:07:08.630965Z"
    },
    "papermill": {
     "duration": 9352.61732,
     "end_time": "2025-05-13T17:07:08.634866",
     "exception": false,
     "start_time": "2025-05-13T14:31:16.017546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 0/450 [00:00<?, ?it/s]/tmp/ipykernel_19/1222697291.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(feature_path, map_location='cpu')\n",
      "Epoch 1/30 [Train]: 100%|██████████| 450/450 [19:34<00:00,  2.61s/it, loss=0.0199]\n",
      "Epoch 1/30 [Val]: 100%|██████████| 150/150 [05:46<00:00,  2.31s/it, val_loss=0.0151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Training Loss: 0.9884, Validation Loss: 0.0139\n",
      "Current learning rate: 0.000500\n",
      "New best validation loss: 0.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 450/450 [17:52<00:00,  2.38s/it, loss=0.0110]\n",
      "Epoch 2/30 [Val]: 100%|██████████| 150/150 [05:53<00:00,  2.35s/it, val_loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30] Training Loss: 0.0160, Validation Loss: 0.0117\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 450/450 [18:00<00:00,  2.40s/it, loss=0.0088]\n",
      "Epoch 3/30 [Val]: 100%|██████████| 150/150 [05:42<00:00,  2.28s/it, val_loss=0.0123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] Training Loss: 0.0142, Validation Loss: 0.0115\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 450/450 [19:27<00:00,  2.59s/it, loss=0.0223]\n",
      "Epoch 4/30 [Val]: 100%|██████████| 150/150 [05:39<00:00,  2.27s/it, val_loss=0.0126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30] Training Loss: 0.0133, Validation Loss: 0.0114\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 450/450 [19:20<00:00,  2.58s/it, loss=0.0140]\n",
      "Epoch 5/30 [Val]: 100%|██████████| 150/150 [06:20<00:00,  2.54s/it, val_loss=0.0112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] Training Loss: 0.0128, Validation Loss: 0.0106\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 4 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 450/450 [17:50<00:00,  2.38s/it, loss=0.0131]\n",
      "Epoch 6/30 [Val]: 100%|██████████| 150/150 [05:09<00:00,  2.07s/it, val_loss=0.0116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/30] Training Loss: 0.0124, Validation Loss: 0.0112\n",
      "Current learning rate: 0.000500\n",
      "No improvement for 5 epochs\n",
      "Early stopping after 6 epochs\n",
      "Training complete.\n",
      "Best validation loss: 0.0139\n",
      "Evaluating best model on test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 150/150 [09:12<00:00,  3.69s/it, loss=0.0053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.0120\n",
      "Overall Character Error Rate: 0.0029\n",
      "Overall Word Error Rate: 0.0130\n",
      "\n",
      "Per-Speaker Metrics:\n",
      "Speaker 17 (samples: 25)\n",
      "  - Character Error Rate: 0.0004\n",
      "  - Word Error Rate: 0.0021\n",
      "Speaker 22 (samples: 24)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0183\n",
      "Speaker 23 (samples: 26)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 28 (samples: 9)\n",
      "  - Character Error Rate: 0.0059\n",
      "  - Word Error Rate: 0.0237\n",
      "Speaker 38 (samples: 28)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0065\n",
      "Speaker 55 (samples: 24)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0065\n",
      "Speaker 64 (samples: 20)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0053\n",
      "Speaker 70 (samples: 21)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0101\n",
      "Speaker 79 (samples: 26)\n",
      "  - Character Error Rate: 0.0043\n",
      "  - Word Error Rate: 0.0236\n",
      "Speaker 81 (samples: 25)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0093\n",
      "Speaker 98 (samples: 26)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0113\n",
      "Speaker 101 (samples: 19)\n",
      "  - Character Error Rate: 0.0065\n",
      "  - Word Error Rate: 0.0267\n",
      "Speaker 112 (samples: 15)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0115\n",
      "Speaker 114 (samples: 20)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0039\n",
      "Speaker 166 (samples: 22)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0074\n",
      "Speaker 175 (samples: 23)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0130\n",
      "Speaker 188 (samples: 24)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0122\n",
      "Speaker 192 (samples: 24)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0028\n",
      "Speaker 203 (samples: 14)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0143\n",
      "Speaker 205 (samples: 27)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0101\n",
      "Speaker 207 (samples: 32)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0104\n",
      "Speaker 209 (samples: 25)\n",
      "  - Character Error Rate: 0.0003\n",
      "  - Word Error Rate: 0.0017\n",
      "Speaker 217 (samples: 17)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0073\n",
      "Speaker 225 (samples: 23)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0089\n",
      "Speaker 227 (samples: 22)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0159\n",
      "Speaker 240 (samples: 21)\n",
      "  - Character Error Rate: 0.0089\n",
      "  - Word Error Rate: 0.0338\n",
      "Speaker 242 (samples: 38)\n",
      "  - Character Error Rate: 0.0044\n",
      "  - Word Error Rate: 0.0201\n",
      "Speaker 249 (samples: 25)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0223\n",
      "Speaker 258 (samples: 23)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0097\n",
      "Speaker 272 (samples: 19)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0051\n",
      "Speaker 274 (samples: 29)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0060\n",
      "Speaker 278 (samples: 19)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0029\n",
      "Speaker 303 (samples: 31)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0042\n",
      "Speaker 318 (samples: 33)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0045\n",
      "Speaker 329 (samples: 18)\n",
      "  - Character Error Rate: 0.0032\n",
      "  - Word Error Rate: 0.0133\n",
      "Speaker 339 (samples: 21)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0137\n",
      "Speaker 359 (samples: 21)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0072\n",
      "Speaker 369 (samples: 20)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0078\n",
      "Speaker 408 (samples: 24)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0060\n",
      "Speaker 434 (samples: 33)\n",
      "  - Character Error Rate: 0.0005\n",
      "  - Word Error Rate: 0.0029\n",
      "Speaker 459 (samples: 26)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0038\n",
      "Speaker 476 (samples: 25)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0090\n",
      "Speaker 479 (samples: 34)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0154\n",
      "Speaker 480 (samples: 26)\n",
      "  - Character Error Rate: 0.0126\n",
      "  - Word Error Rate: 0.0274\n",
      "Speaker 512 (samples: 25)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0164\n",
      "Speaker 543 (samples: 24)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0047\n",
      "Speaker 583 (samples: 22)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0121\n",
      "Speaker 594 (samples: 22)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0104\n",
      "Speaker 596 (samples: 31)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0055\n",
      "Speaker 606 (samples: 23)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0162\n",
      "Speaker 664 (samples: 20)\n",
      "  - Character Error Rate: 0.0067\n",
      "  - Word Error Rate: 0.0271\n",
      "Speaker 666 (samples: 15)\n",
      "  - Character Error Rate: 0.0033\n",
      "  - Word Error Rate: 0.0123\n",
      "Speaker 667 (samples: 27)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0081\n",
      "Speaker 688 (samples: 24)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0061\n",
      "Speaker 698 (samples: 17)\n",
      "  - Character Error Rate: 0.0057\n",
      "  - Word Error Rate: 0.0169\n",
      "Speaker 699 (samples: 25)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0069\n",
      "Speaker 707 (samples: 26)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0065\n",
      "Speaker 718 (samples: 25)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0034\n",
      "Speaker 724 (samples: 27)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0042\n",
      "Speaker 815 (samples: 11)\n",
      "  - Character Error Rate: 0.0044\n",
      "  - Word Error Rate: 0.0199\n",
      "Speaker 816 (samples: 18)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0055\n",
      "Speaker 820 (samples: 19)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0069\n",
      "Speaker 829 (samples: 37)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0164\n",
      "Speaker 850 (samples: 25)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0060\n",
      "Speaker 899 (samples: 23)\n",
      "  - Character Error Rate: 0.0036\n",
      "  - Word Error Rate: 0.0100\n",
      "Speaker 920 (samples: 17)\n",
      "  - Character Error Rate: 0.0005\n",
      "  - Word Error Rate: 0.0025\n",
      "Speaker 925 (samples: 26)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0034\n",
      "Speaker 949 (samples: 24)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0131\n",
      "Speaker 954 (samples: 19)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0083\n",
      "Speaker 979 (samples: 13)\n",
      "  - Character Error Rate: 0.0083\n",
      "  - Word Error Rate: 0.0259\n",
      "Speaker 1001 (samples: 22)\n",
      "  - Character Error Rate: 0.0043\n",
      "  - Word Error Rate: 0.0278\n",
      "Speaker 1018 (samples: 20)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0063\n",
      "Speaker 1025 (samples: 21)\n",
      "  - Character Error Rate: 0.0048\n",
      "  - Word Error Rate: 0.0252\n",
      "Speaker 1027 (samples: 20)\n",
      "  - Character Error Rate: 0.0003\n",
      "  - Word Error Rate: 0.0014\n",
      "Speaker 1053 (samples: 25)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0055\n",
      "Speaker 1058 (samples: 27)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0055\n",
      "Speaker 1079 (samples: 24)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0049\n",
      "Speaker 1093 (samples: 32)\n",
      "  - Character Error Rate: 0.0094\n",
      "  - Word Error Rate: 0.0301\n",
      "Speaker 1100 (samples: 24)\n",
      "  - Character Error Rate: 0.0057\n",
      "  - Word Error Rate: 0.0185\n",
      "Speaker 1121 (samples: 26)\n",
      "  - Character Error Rate: 0.0047\n",
      "  - Word Error Rate: 0.0207\n",
      "Speaker 1165 (samples: 29)\n",
      "  - Character Error Rate: 0.0025\n",
      "  - Word Error Rate: 0.0092\n",
      "Speaker 1224 (samples: 21)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0187\n",
      "Speaker 1226 (samples: 26)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0077\n",
      "Speaker 1259 (samples: 28)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0052\n",
      "Speaker 1264 (samples: 34)\n",
      "  - Character Error Rate: 0.0036\n",
      "  - Word Error Rate: 0.0190\n",
      "Speaker 1265 (samples: 23)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0171\n",
      "Speaker 1271 (samples: 20)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0040\n",
      "Speaker 1283 (samples: 28)\n",
      "  - Character Error Rate: 0.0040\n",
      "  - Word Error Rate: 0.0186\n",
      "Speaker 1289 (samples: 31)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0134\n",
      "Speaker 1290 (samples: 17)\n",
      "  - Character Error Rate: 0.0063\n",
      "  - Word Error Rate: 0.0285\n",
      "Speaker 1311 (samples: 24)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0099\n",
      "Speaker 1316 (samples: 22)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0090\n",
      "Speaker 1322 (samples: 24)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0052\n",
      "Speaker 1335 (samples: 19)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0054\n",
      "Speaker 1336 (samples: 25)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0066\n",
      "Speaker 1343 (samples: 21)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0070\n",
      "Speaker 1348 (samples: 24)\n",
      "  - Character Error Rate: 0.0149\n",
      "  - Word Error Rate: 0.0349\n",
      "Speaker 1382 (samples: 15)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0181\n",
      "Speaker 1390 (samples: 20)\n",
      "  - Character Error Rate: 0.0080\n",
      "  - Word Error Rate: 0.0195\n",
      "Speaker 1392 (samples: 20)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0078\n",
      "Speaker 1413 (samples: 25)\n",
      "  - Character Error Rate: 0.0043\n",
      "  - Word Error Rate: 0.0153\n",
      "Speaker 1422 (samples: 22)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0134\n",
      "Speaker 1446 (samples: 20)\n",
      "  - Character Error Rate: 0.0005\n",
      "  - Word Error Rate: 0.0027\n",
      "Speaker 1460 (samples: 20)\n",
      "  - Character Error Rate: 0.0066\n",
      "  - Word Error Rate: 0.0346\n",
      "Speaker 1463 (samples: 34)\n",
      "  - Character Error Rate: 0.0042\n",
      "  - Word Error Rate: 0.0154\n",
      "Speaker 1487 (samples: 21)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0116\n",
      "Speaker 1498 (samples: 22)\n",
      "  - Character Error Rate: 0.0069\n",
      "  - Word Error Rate: 0.0306\n",
      "Speaker 1535 (samples: 24)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0030\n",
      "Speaker 1547 (samples: 14)\n",
      "  - Character Error Rate: 0.0077\n",
      "  - Word Error Rate: 0.0402\n",
      "Speaker 1556 (samples: 24)\n",
      "  - Character Error Rate: 0.0099\n",
      "  - Word Error Rate: 0.0332\n",
      "Speaker 1629 (samples: 28)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0049\n",
      "Speaker 1634 (samples: 9)\n",
      "  - Character Error Rate: 0.0057\n",
      "  - Word Error Rate: 0.0286\n",
      "Speaker 1639 (samples: 26)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0031\n",
      "Speaker 1645 (samples: 5)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0125\n",
      "Speaker 1649 (samples: 33)\n",
      "  - Character Error Rate: 0.0032\n",
      "  - Word Error Rate: 0.0175\n",
      "Speaker 1668 (samples: 21)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0077\n",
      "Speaker 1678 (samples: 18)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0062\n",
      "Speaker 1705 (samples: 20)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0044\n",
      "Speaker 1731 (samples: 21)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0076\n",
      "Speaker 1740 (samples: 23)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0098\n",
      "Speaker 1754 (samples: 25)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0095\n",
      "Speaker 1779 (samples: 19)\n",
      "  - Character Error Rate: 0.0050\n",
      "  - Word Error Rate: 0.0254\n",
      "Speaker 1801 (samples: 17)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0102\n",
      "Speaker 1827 (samples: 12)\n",
      "  - Character Error Rate: 0.0036\n",
      "  - Word Error Rate: 0.0207\n",
      "Speaker 1845 (samples: 20)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0163\n",
      "Speaker 1851 (samples: 21)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0158\n",
      "Speaker 1859 (samples: 25)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0033\n",
      "Speaker 1874 (samples: 25)\n",
      "  - Character Error Rate: 0.0048\n",
      "  - Word Error Rate: 0.0240\n",
      "Speaker 1885 (samples: 15)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0113\n",
      "Speaker 1913 (samples: 22)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0161\n",
      "Speaker 1923 (samples: 24)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0147\n",
      "Speaker 1944 (samples: 24)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0155\n",
      "Speaker 1958 (samples: 22)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0071\n",
      "Speaker 1961 (samples: 18)\n",
      "  - Character Error Rate: 0.0072\n",
      "  - Word Error Rate: 0.0184\n",
      "Speaker 1974 (samples: 28)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0066\n",
      "Speaker 1987 (samples: 24)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0182\n",
      "Speaker 2004 (samples: 21)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0191\n",
      "Speaker 2010 (samples: 19)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0050\n",
      "Speaker 2012 (samples: 24)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0237\n",
      "Speaker 2045 (samples: 28)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0074\n",
      "Speaker 2053 (samples: 29)\n",
      "  - Character Error Rate: 0.0027\n",
      "  - Word Error Rate: 0.0113\n",
      "Speaker 2056 (samples: 21)\n",
      "  - Character Error Rate: 0.0004\n",
      "  - Word Error Rate: 0.0022\n",
      "Speaker 2061 (samples: 27)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0157\n",
      "Speaker 2113 (samples: 24)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0087\n",
      "Speaker 2127 (samples: 20)\n",
      "  - Character Error Rate: 0.0008\n",
      "  - Word Error Rate: 0.0039\n",
      "Speaker 2146 (samples: 10)\n",
      "  - Character Error Rate: 0.0004\n",
      "  - Word Error Rate: 0.0026\n",
      "Speaker 2162 (samples: 26)\n",
      "  - Character Error Rate: 0.0035\n",
      "  - Word Error Rate: 0.0134\n",
      "Speaker 2194 (samples: 25)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0194\n",
      "Speaker 2201 (samples: 25)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0065\n",
      "Speaker 2229 (samples: 24)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0046\n",
      "Speaker 2254 (samples: 24)\n",
      "  - Character Error Rate: 0.0073\n",
      "  - Word Error Rate: 0.0356\n",
      "Speaker 2269 (samples: 20)\n",
      "  - Character Error Rate: 0.0056\n",
      "  - Word Error Rate: 0.0196\n",
      "Speaker 2272 (samples: 28)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0068\n",
      "Speaker 2294 (samples: 27)\n",
      "  - Character Error Rate: 0.0064\n",
      "  - Word Error Rate: 0.0231\n",
      "Speaker 2299 (samples: 22)\n",
      "  - Character Error Rate: 0.0042\n",
      "  - Word Error Rate: 0.0167\n",
      "Speaker 2319 (samples: 23)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0075\n",
      "Speaker 2368 (samples: 34)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0111\n",
      "Speaker 2388 (samples: 28)\n",
      "  - Character Error Rate: 0.0064\n",
      "  - Word Error Rate: 0.0211\n",
      "Speaker 2393 (samples: 18)\n",
      "  - Character Error Rate: 0.0049\n",
      "  - Word Error Rate: 0.0163\n",
      "Speaker 2404 (samples: 29)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0172\n",
      "Speaker 2473 (samples: 19)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0086\n",
      "Speaker 2481 (samples: 20)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0121\n",
      "Speaker 2531 (samples: 26)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0056\n",
      "Speaker 2532 (samples: 21)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0140\n",
      "Speaker 2533 (samples: 19)\n",
      "  - Character Error Rate: 0.0038\n",
      "  - Word Error Rate: 0.0066\n",
      "Speaker 2562 (samples: 24)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0051\n",
      "Speaker 2581 (samples: 23)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0101\n",
      "Speaker 2582 (samples: 25)\n",
      "  - Character Error Rate: 0.0038\n",
      "  - Word Error Rate: 0.0154\n",
      "Speaker 2589 (samples: 14)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0131\n",
      "Speaker 2592 (samples: 20)\n",
      "  - Character Error Rate: 0.0027\n",
      "  - Word Error Rate: 0.0125\n",
      "Speaker 2618 (samples: 23)\n",
      "  - Character Error Rate: 0.0042\n",
      "  - Word Error Rate: 0.0141\n",
      "Speaker 2628 (samples: 24)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0120\n",
      "Speaker 2638 (samples: 27)\n",
      "  - Character Error Rate: 0.0035\n",
      "  - Word Error Rate: 0.0223\n",
      "Speaker 2652 (samples: 20)\n",
      "  - Character Error Rate: 0.0106\n",
      "  - Word Error Rate: 0.0449\n",
      "Speaker 2654 (samples: 19)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0060\n",
      "Speaker 2673 (samples: 20)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0039\n",
      "Speaker 2674 (samples: 14)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0107\n",
      "Speaker 2751 (samples: 20)\n",
      "  - Character Error Rate: 0.0047\n",
      "  - Word Error Rate: 0.0178\n",
      "Speaker 2785 (samples: 18)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0178\n",
      "Speaker 2787 (samples: 22)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 2790 (samples: 31)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0091\n",
      "Speaker 2816 (samples: 16)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0169\n",
      "Speaker 2823 (samples: 19)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0165\n",
      "Speaker 2827 (samples: 18)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0095\n",
      "Speaker 2882 (samples: 21)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0142\n",
      "Speaker 2920 (samples: 22)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0089\n",
      "Speaker 2929 (samples: 18)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0039\n",
      "Speaker 2960 (samples: 16)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0135\n",
      "Speaker 2992 (samples: 21)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0110\n",
      "Speaker 2999 (samples: 24)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0111\n",
      "Speaker 3008 (samples: 29)\n",
      "  - Character Error Rate: 0.0025\n",
      "  - Word Error Rate: 0.0116\n",
      "Speaker 3046 (samples: 24)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0126\n",
      "Speaker 3070 (samples: 18)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0150\n",
      "Speaker 3094 (samples: 26)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 3105 (samples: 31)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0110\n",
      "Speaker 3118 (samples: 24)\n",
      "  - Character Error Rate: 0.0002\n",
      "  - Word Error Rate: 0.0026\n",
      "Speaker 3157 (samples: 21)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0060\n",
      "Speaker 3180 (samples: 26)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0088\n",
      "Speaker 3185 (samples: 23)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0026\n",
      "Speaker 3230 (samples: 23)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0042\n",
      "Speaker 3274 (samples: 25)\n",
      "  - Character Error Rate: 0.0035\n",
      "  - Word Error Rate: 0.0138\n",
      "Speaker 3294 (samples: 16)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0110\n",
      "Speaker 3328 (samples: 21)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0075\n",
      "Speaker 3330 (samples: 19)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0095\n",
      "Speaker 3347 (samples: 13)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0057\n",
      "Speaker 3370 (samples: 22)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0099\n",
      "Speaker 3380 (samples: 19)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0059\n",
      "Speaker 3389 (samples: 43)\n",
      "  - Character Error Rate: 0.0050\n",
      "  - Word Error Rate: 0.0156\n",
      "Speaker 3446 (samples: 16)\n",
      "  - Character Error Rate: 0.0059\n",
      "  - Word Error Rate: 0.0236\n",
      "Speaker 3482 (samples: 29)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0112\n",
      "Speaker 3483 (samples: 22)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0147\n",
      "Speaker 3513 (samples: 28)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0077\n",
      "Speaker 3521 (samples: 26)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0147\n",
      "Speaker 3540 (samples: 23)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0020\n",
      "Speaker 3549 (samples: 27)\n",
      "  - Character Error Rate: 0.0063\n",
      "  - Word Error Rate: 0.0275\n",
      "Speaker 3551 (samples: 22)\n",
      "  - Character Error Rate: 0.0035\n",
      "  - Word Error Rate: 0.0174\n",
      "Speaker 3630 (samples: 14)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0049\n",
      "Speaker 3638 (samples: 25)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0066\n",
      "Speaker 3654 (samples: 31)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0177\n",
      "Speaker 3703 (samples: 26)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0027\n",
      "Speaker 3717 (samples: 20)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0053\n",
      "Speaker 3733 (samples: 30)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0111\n",
      "Speaker 3738 (samples: 20)\n",
      "  - Character Error Rate: 0.0085\n",
      "  - Word Error Rate: 0.0374\n",
      "Speaker 3825 (samples: 13)\n",
      "  - Character Error Rate: 0.0064\n",
      "  - Word Error Rate: 0.0164\n",
      "Speaker 3851 (samples: 24)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0151\n",
      "Speaker 3852 (samples: 22)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0073\n",
      "Speaker 3864 (samples: 19)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0148\n",
      "Speaker 3869 (samples: 24)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0079\n",
      "Speaker 3876 (samples: 21)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0100\n",
      "Speaker 3889 (samples: 25)\n",
      "  - Character Error Rate: 0.0038\n",
      "  - Word Error Rate: 0.0171\n",
      "Speaker 3905 (samples: 17)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0104\n",
      "Speaker 3914 (samples: 19)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0062\n",
      "Speaker 3923 (samples: 26)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0059\n",
      "Speaker 3927 (samples: 25)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0092\n",
      "Speaker 3945 (samples: 18)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0119\n",
      "Speaker 3967 (samples: 25)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0044\n",
      "Speaker 3977 (samples: 25)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0102\n",
      "Speaker 3989 (samples: 25)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0043\n",
      "Speaker 3994 (samples: 20)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0094\n",
      "Speaker 4010 (samples: 19)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0047\n",
      "Speaker 4044 (samples: 16)\n",
      "  - Character Error Rate: 0.0025\n",
      "  - Word Error Rate: 0.0181\n",
      "Speaker 4054 (samples: 17)\n",
      "  - Character Error Rate: 0.0027\n",
      "  - Word Error Rate: 0.0097\n",
      "Speaker 4098 (samples: 19)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0097\n",
      "Speaker 4108 (samples: 27)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0088\n",
      "Speaker 4110 (samples: 26)\n",
      "  - Character Error Rate: 0.0038\n",
      "  - Word Error Rate: 0.0184\n",
      "Speaker 4116 (samples: 17)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0109\n",
      "Speaker 4138 (samples: 23)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0101\n",
      "Speaker 4145 (samples: 28)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0104\n",
      "Speaker 4148 (samples: 30)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0097\n",
      "Speaker 4152 (samples: 22)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0127\n",
      "Speaker 4226 (samples: 21)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0089\n",
      "Speaker 4236 (samples: 15)\n",
      "  - Character Error Rate: 0.0027\n",
      "  - Word Error Rate: 0.0093\n",
      "Speaker 4238 (samples: 20)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0088\n",
      "Speaker 4246 (samples: 11)\n",
      "  - Character Error Rate: 0.0051\n",
      "  - Word Error Rate: 0.0145\n",
      "Speaker 4278 (samples: 27)\n",
      "  - Character Error Rate: 0.0003\n",
      "  - Word Error Rate: 0.0015\n",
      "Speaker 4289 (samples: 31)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0100\n",
      "Speaker 4363 (samples: 16)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0065\n",
      "Speaker 4425 (samples: 14)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0107\n",
      "Speaker 4434 (samples: 24)\n",
      "  - Character Error Rate: 0.0042\n",
      "  - Word Error Rate: 0.0291\n",
      "Speaker 4438 (samples: 19)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0195\n",
      "Speaker 4519 (samples: 24)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0064\n",
      "Speaker 4535 (samples: 25)\n",
      "  - Character Error Rate: 0.0046\n",
      "  - Word Error Rate: 0.0220\n",
      "Speaker 4586 (samples: 29)\n",
      "  - Character Error Rate: 0.0206\n",
      "  - Word Error Rate: 0.0976\n",
      "Speaker 4590 (samples: 31)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0128\n",
      "Speaker 4595 (samples: 29)\n",
      "  - Character Error Rate: 0.0033\n",
      "  - Word Error Rate: 0.0263\n",
      "Speaker 4598 (samples: 15)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0075\n",
      "Speaker 4681 (samples: 18)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0044\n",
      "Speaker 4770 (samples: 21)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0175\n",
      "Speaker 4806 (samples: 16)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0151\n",
      "Speaker 4837 (samples: 17)\n",
      "  - Character Error Rate: 0.0005\n",
      "  - Word Error Rate: 0.0044\n",
      "Speaker 4839 (samples: 20)\n",
      "  - Character Error Rate: 0.0050\n",
      "  - Word Error Rate: 0.0184\n",
      "Speaker 4926 (samples: 24)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0062\n",
      "Speaker 4967 (samples: 19)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0145\n",
      "Speaker 5012 (samples: 26)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0096\n",
      "Speaker 5062 (samples: 20)\n",
      "  - Character Error Rate: 0.0000\n",
      "  - Word Error Rate: 0.0000\n",
      "Speaker 5063 (samples: 9)\n",
      "  - Character Error Rate: 0.0124\n",
      "  - Word Error Rate: 0.0590\n",
      "Speaker 5093 (samples: 27)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0115\n",
      "Speaker 5115 (samples: 36)\n",
      "  - Character Error Rate: 0.0069\n",
      "  - Word Error Rate: 0.0299\n",
      "Speaker 5126 (samples: 19)\n",
      "  - Character Error Rate: 0.0032\n",
      "  - Word Error Rate: 0.0112\n",
      "Speaker 5133 (samples: 23)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0047\n",
      "Speaker 5157 (samples: 22)\n",
      "  - Character Error Rate: 0.0057\n",
      "  - Word Error Rate: 0.0298\n",
      "Speaker 5186 (samples: 18)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0125\n",
      "Speaker 5190 (samples: 24)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0111\n",
      "Speaker 5239 (samples: 24)\n",
      "  - Character Error Rate: 0.0100\n",
      "  - Word Error Rate: 0.0299\n",
      "Speaker 5261 (samples: 27)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0141\n",
      "Speaker 5290 (samples: 21)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0068\n",
      "Speaker 5401 (samples: 30)\n",
      "  - Character Error Rate: 0.0071\n",
      "  - Word Error Rate: 0.0311\n",
      "Speaker 5448 (samples: 25)\n",
      "  - Character Error Rate: 0.0004\n",
      "  - Word Error Rate: 0.0022\n",
      "Speaker 5519 (samples: 23)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 5618 (samples: 31)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0061\n",
      "Speaker 5622 (samples: 29)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0146\n",
      "Speaker 5637 (samples: 17)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0121\n",
      "Speaker 5656 (samples: 23)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0085\n",
      "Speaker 5672 (samples: 28)\n",
      "  - Character Error Rate: 0.0052\n",
      "  - Word Error Rate: 0.0202\n",
      "Speaker 5684 (samples: 30)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0189\n",
      "Speaker 5712 (samples: 23)\n",
      "  - Character Error Rate: 0.0006\n",
      "  - Word Error Rate: 0.0025\n",
      "Speaker 5723 (samples: 27)\n",
      "  - Character Error Rate: 0.0025\n",
      "  - Word Error Rate: 0.0089\n",
      "Speaker 5727 (samples: 31)\n",
      "  - Character Error Rate: 0.0048\n",
      "  - Word Error Rate: 0.0274\n",
      "Speaker 5731 (samples: 27)\n",
      "  - Character Error Rate: 0.0046\n",
      "  - Word Error Rate: 0.0243\n",
      "Speaker 5740 (samples: 29)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0128\n",
      "Speaker 5767 (samples: 21)\n",
      "  - Character Error Rate: 0.0025\n",
      "  - Word Error Rate: 0.0135\n",
      "Speaker 5776 (samples: 24)\n",
      "  - Character Error Rate: 0.0124\n",
      "  - Word Error Rate: 0.0547\n",
      "Speaker 5802 (samples: 27)\n",
      "  - Character Error Rate: 0.0043\n",
      "  - Word Error Rate: 0.0205\n",
      "Speaker 5914 (samples: 26)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0087\n",
      "Speaker 5935 (samples: 20)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0103\n",
      "Speaker 5968 (samples: 16)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0175\n",
      "Speaker 6060 (samples: 23)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0085\n",
      "Speaker 6082 (samples: 20)\n",
      "  - Character Error Rate: 0.0026\n",
      "  - Word Error Rate: 0.0105\n",
      "Speaker 6104 (samples: 28)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0226\n",
      "Speaker 6119 (samples: 23)\n",
      "  - Character Error Rate: 0.0040\n",
      "  - Word Error Rate: 0.0090\n",
      "Speaker 6139 (samples: 21)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0241\n",
      "Speaker 6157 (samples: 25)\n",
      "  - Character Error Rate: 0.0067\n",
      "  - Word Error Rate: 0.0233\n",
      "Speaker 6233 (samples: 36)\n",
      "  - Character Error Rate: 0.0104\n",
      "  - Word Error Rate: 0.0417\n",
      "Speaker 6235 (samples: 20)\n",
      "  - Character Error Rate: 0.0079\n",
      "  - Word Error Rate: 0.0375\n",
      "Speaker 6258 (samples: 18)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0071\n",
      "Speaker 6286 (samples: 13)\n",
      "  - Character Error Rate: 0.0046\n",
      "  - Word Error Rate: 0.0190\n",
      "Speaker 6308 (samples: 22)\n",
      "  - Character Error Rate: 0.0008\n",
      "  - Word Error Rate: 0.0054\n",
      "Speaker 6339 (samples: 28)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0096\n",
      "Speaker 6352 (samples: 18)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0117\n",
      "Speaker 6359 (samples: 13)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0019\n",
      "Speaker 6373 (samples: 22)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0116\n",
      "Speaker 6378 (samples: 27)\n",
      "  - Character Error Rate: 0.0139\n",
      "  - Word Error Rate: 0.0528\n",
      "Speaker 6395 (samples: 26)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0184\n",
      "Speaker 6446 (samples: 30)\n",
      "  - Character Error Rate: 0.0074\n",
      "  - Word Error Rate: 0.0304\n",
      "Speaker 6458 (samples: 35)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0158\n",
      "Speaker 6494 (samples: 23)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0131\n",
      "Speaker 6499 (samples: 31)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0108\n",
      "Speaker 6505 (samples: 26)\n",
      "  - Character Error Rate: 0.0053\n",
      "  - Word Error Rate: 0.0269\n",
      "Speaker 6509 (samples: 24)\n",
      "  - Character Error Rate: 0.0048\n",
      "  - Word Error Rate: 0.0198\n",
      "Speaker 6538 (samples: 19)\n",
      "  - Character Error Rate: 0.0029\n",
      "  - Word Error Rate: 0.0149\n",
      "Speaker 6544 (samples: 29)\n",
      "  - Character Error Rate: 0.0039\n",
      "  - Word Error Rate: 0.0178\n",
      "Speaker 6555 (samples: 22)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0035\n",
      "Speaker 6567 (samples: 20)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0050\n",
      "Speaker 6574 (samples: 25)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0036\n",
      "Speaker 6575 (samples: 26)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0098\n",
      "Speaker 6620 (samples: 13)\n",
      "  - Character Error Rate: 0.0046\n",
      "  - Word Error Rate: 0.0173\n",
      "Speaker 6637 (samples: 27)\n",
      "  - Character Error Rate: 0.0005\n",
      "  - Word Error Rate: 0.0015\n",
      "Speaker 6686 (samples: 22)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0121\n",
      "Speaker 6690 (samples: 20)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0029\n",
      "Speaker 6782 (samples: 20)\n",
      "  - Character Error Rate: 0.0050\n",
      "  - Word Error Rate: 0.0218\n",
      "Speaker 6877 (samples: 23)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0070\n",
      "Speaker 6895 (samples: 25)\n",
      "  - Character Error Rate: 0.0072\n",
      "  - Word Error Rate: 0.0284\n",
      "Speaker 6904 (samples: 15)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0097\n",
      "Speaker 6927 (samples: 15)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0034\n",
      "Speaker 6937 (samples: 17)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0037\n",
      "Speaker 6965 (samples: 18)\n",
      "  - Character Error Rate: 0.0000\n",
      "  - Word Error Rate: 0.0000\n",
      "Speaker 7061 (samples: 27)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0058\n",
      "Speaker 7095 (samples: 24)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0087\n",
      "Speaker 7120 (samples: 24)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0207\n",
      "Speaker 7134 (samples: 31)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0053\n",
      "Speaker 7140 (samples: 19)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0103\n",
      "Speaker 7145 (samples: 14)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0079\n",
      "Speaker 7240 (samples: 20)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0075\n",
      "Speaker 7241 (samples: 27)\n",
      "  - Character Error Rate: 0.0014\n",
      "  - Word Error Rate: 0.0108\n",
      "Speaker 7247 (samples: 18)\n",
      "  - Character Error Rate: 0.0065\n",
      "  - Word Error Rate: 0.0247\n",
      "Speaker 7258 (samples: 23)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0094\n",
      "Speaker 7286 (samples: 14)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0085\n",
      "Speaker 7297 (samples: 13)\n",
      "  - Character Error Rate: 0.0051\n",
      "  - Word Error Rate: 0.0208\n",
      "Speaker 7313 (samples: 15)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0090\n",
      "Speaker 7335 (samples: 17)\n",
      "  - Character Error Rate: 0.0003\n",
      "  - Word Error Rate: 0.0015\n",
      "Speaker 7342 (samples: 22)\n",
      "  - Character Error Rate: 0.0060\n",
      "  - Word Error Rate: 0.0237\n",
      "Speaker 7395 (samples: 19)\n",
      "  - Character Error Rate: 0.0018\n",
      "  - Word Error Rate: 0.0130\n",
      "Speaker 7478 (samples: 23)\n",
      "  - Character Error Rate: 0.0059\n",
      "  - Word Error Rate: 0.0301\n",
      "Speaker 7498 (samples: 12)\n",
      "  - Character Error Rate: 0.0000\n",
      "  - Word Error Rate: 0.0000\n",
      "Speaker 7515 (samples: 20)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0041\n",
      "Speaker 7520 (samples: 19)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0140\n",
      "Speaker 7540 (samples: 32)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0095\n",
      "Speaker 7553 (samples: 23)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0058\n",
      "Speaker 7555 (samples: 22)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0058\n",
      "Speaker 7594 (samples: 28)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0176\n",
      "Speaker 7665 (samples: 25)\n",
      "  - Character Error Rate: 0.0023\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 7705 (samples: 25)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0213\n",
      "Speaker 7717 (samples: 23)\n",
      "  - Character Error Rate: 0.0047\n",
      "  - Word Error Rate: 0.0186\n",
      "Speaker 7720 (samples: 20)\n",
      "  - Character Error Rate: 0.0032\n",
      "  - Word Error Rate: 0.0092\n",
      "Speaker 7766 (samples: 27)\n",
      "  - Character Error Rate: 0.0041\n",
      "  - Word Error Rate: 0.0178\n",
      "Speaker 7783 (samples: 17)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0084\n",
      "Speaker 7789 (samples: 19)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0174\n",
      "Speaker 7802 (samples: 19)\n",
      "  - Character Error Rate: 0.0027\n",
      "  - Word Error Rate: 0.0058\n",
      "Speaker 7809 (samples: 25)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0103\n",
      "Speaker 7825 (samples: 14)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0053\n",
      "Speaker 7867 (samples: 25)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0072\n",
      "Speaker 7874 (samples: 24)\n",
      "  - Character Error Rate: 0.0017\n",
      "  - Word Error Rate: 0.0122\n",
      "Speaker 7926 (samples: 26)\n",
      "  - Character Error Rate: 0.0066\n",
      "  - Word Error Rate: 0.0264\n",
      "Speaker 7932 (samples: 20)\n",
      "  - Character Error Rate: 0.0002\n",
      "  - Word Error Rate: 0.0010\n",
      "Speaker 7933 (samples: 31)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0124\n",
      "Speaker 7938 (samples: 22)\n",
      "  - Character Error Rate: 0.0024\n",
      "  - Word Error Rate: 0.0114\n",
      "Speaker 7939 (samples: 26)\n",
      "  - Character Error Rate: 0.0002\n",
      "  - Word Error Rate: 0.0009\n",
      "Speaker 7956 (samples: 19)\n",
      "  - Character Error Rate: 0.0004\n",
      "  - Word Error Rate: 0.0011\n",
      "Speaker 7962 (samples: 23)\n",
      "  - Character Error Rate: 0.0031\n",
      "  - Word Error Rate: 0.0107\n",
      "Speaker 7967 (samples: 15)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0136\n",
      "Speaker 7982 (samples: 29)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0107\n",
      "Speaker 8006 (samples: 18)\n",
      "  - Character Error Rate: 0.0038\n",
      "  - Word Error Rate: 0.0123\n",
      "Speaker 8008 (samples: 22)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0149\n",
      "Speaker 8011 (samples: 30)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0089\n",
      "Speaker 8050 (samples: 18)\n",
      "  - Character Error Rate: 0.0051\n",
      "  - Word Error Rate: 0.0159\n",
      "Speaker 8075 (samples: 14)\n",
      "  - Character Error Rate: 0.0007\n",
      "  - Word Error Rate: 0.0037\n",
      "Speaker 8080 (samples: 19)\n",
      "  - Character Error Rate: 0.0010\n",
      "  - Word Error Rate: 0.0027\n",
      "Speaker 8097 (samples: 23)\n",
      "  - Character Error Rate: 0.0008\n",
      "  - Word Error Rate: 0.0013\n",
      "Speaker 8138 (samples: 17)\n",
      "  - Character Error Rate: 0.0034\n",
      "  - Word Error Rate: 0.0105\n",
      "Speaker 8142 (samples: 22)\n",
      "  - Character Error Rate: 0.0012\n",
      "  - Word Error Rate: 0.0078\n",
      "Speaker 8152 (samples: 21)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0085\n",
      "Speaker 8183 (samples: 19)\n",
      "  - Character Error Rate: 0.0037\n",
      "  - Word Error Rate: 0.0219\n",
      "Speaker 8190 (samples: 26)\n",
      "  - Character Error Rate: 0.0036\n",
      "  - Word Error Rate: 0.0196\n",
      "Speaker 8194 (samples: 21)\n",
      "  - Character Error Rate: 0.0042\n",
      "  - Word Error Rate: 0.0212\n",
      "Speaker 8195 (samples: 25)\n",
      "  - Character Error Rate: 0.0022\n",
      "  - Word Error Rate: 0.0126\n",
      "Speaker 8228 (samples: 7)\n",
      "  - Character Error Rate: 0.0000\n",
      "  - Word Error Rate: 0.0000\n",
      "Speaker 8266 (samples: 24)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0057\n",
      "Speaker 8329 (samples: 17)\n",
      "  - Character Error Rate: 0.0000\n",
      "  - Word Error Rate: 0.0000\n",
      "Speaker 8347 (samples: 22)\n",
      "  - Character Error Rate: 0.0060\n",
      "  - Word Error Rate: 0.0270\n",
      "Speaker 8388 (samples: 26)\n",
      "  - Character Error Rate: 0.0016\n",
      "  - Word Error Rate: 0.0080\n",
      "Speaker 8396 (samples: 23)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0031\n",
      "Speaker 8459 (samples: 22)\n",
      "  - Character Error Rate: 0.0045\n",
      "  - Word Error Rate: 0.0215\n",
      "Speaker 8464 (samples: 17)\n",
      "  - Character Error Rate: 0.0088\n",
      "  - Word Error Rate: 0.0373\n",
      "Speaker 8479 (samples: 15)\n",
      "  - Character Error Rate: 0.0028\n",
      "  - Word Error Rate: 0.0125\n",
      "Speaker 8506 (samples: 21)\n",
      "  - Character Error Rate: 0.0030\n",
      "  - Word Error Rate: 0.0121\n",
      "Speaker 8534 (samples: 16)\n",
      "  - Character Error Rate: 0.0020\n",
      "  - Word Error Rate: 0.0070\n",
      "Speaker 8545 (samples: 18)\n",
      "  - Character Error Rate: 0.0015\n",
      "  - Word Error Rate: 0.0038\n",
      "Speaker 8591 (samples: 18)\n",
      "  - Character Error Rate: 0.0033\n",
      "  - Word Error Rate: 0.0094\n",
      "Speaker 8699 (samples: 20)\n",
      "  - Character Error Rate: 0.0009\n",
      "  - Word Error Rate: 0.0049\n",
      "Speaker 8705 (samples: 24)\n",
      "  - Character Error Rate: 0.0021\n",
      "  - Word Error Rate: 0.0088\n",
      "Speaker 8713 (samples: 19)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0134\n",
      "Speaker 8771 (samples: 19)\n",
      "  - Character Error Rate: 0.0064\n",
      "  - Word Error Rate: 0.0142\n",
      "Speaker 8776 (samples: 19)\n",
      "  - Character Error Rate: 0.0011\n",
      "  - Word Error Rate: 0.0047\n",
      "Speaker 8824 (samples: 26)\n",
      "  - Character Error Rate: 0.0019\n",
      "  - Word Error Rate: 0.0068\n",
      "Speaker 8825 (samples: 15)\n",
      "  - Character Error Rate: 0.0052\n",
      "  - Word Error Rate: 0.0354\n",
      "Speaker 8848 (samples: 22)\n",
      "  - Character Error Rate: 0.0013\n",
      "  - Word Error Rate: 0.0068\n",
      "Speaker 8879 (samples: 28)\n",
      "  - Character Error Rate: 0.0044\n",
      "  - Word Error Rate: 0.0221\n",
      "Example 1 (Speaker: 2404):\n",
      "Reference: 'unless you call on the radio in which case we come in with the automatics going and shoot the place up and it doesnt matter who we hit this will be done only as a last resort'\n",
      "Prediction: 'unless you call on the radio in which case we come in with the automatics going and shoot the place up and it doesnt matter who we hit this will be done only as a last resort'\n",
      "Example 2 (Speaker: 3989):\n",
      "Reference: 'oh very indignant indeed she decided that mister rabbit should be punished very severely but as she watched him sitting there dreaming in the warm sunshine her anger began to melt away the fact is'\n",
      "Prediction: 'oh very indignant indeed she decided that mister rabbit should be punished very severely but as she watched him sitting there dreaming in the warm sunshine her anger began to melt away the fact is'\n",
      "Example 3 (Speaker: 4434):\n",
      "Reference: 'with here and there a single flowering streamer making a tiny wreath on its own account on the southern sides of the same gateway are two large bushes of the mexican orange flower choisya ternata loaded with its orange like bloom'\n",
      "Prediction: 'with here and there a single flowering streamer making a tiny wreath on its own account on the southern sides of the same gateway are two large bushes of the mexican orange flower choisia turnata loaded with its orange like bloom'\n",
      "Example 4 (Speaker: 5712):\n",
      "Reference: 'putting her hand inside her mothers arm thats true enough oh my darling forgive me said the mother suddenly remembering that the use of the old proverb at the present moment had been almost cruel do not mind it said lily'\n",
      "Prediction: 'putting her hand inside her mothers arm thats true enough oh my darling forgive me said the mother suddenly remembering that the use of the old proverb at the present moment had been almost cruel do not mind it said lily'\n",
      "Example 5 (Speaker: 7933):\n",
      "Reference: 'kit was arrested and the note of course was found on his person the evidence seemed so strong that the poor fellow was quickly tried found guilty and sentenced to prison for a long time all might have gone wrong but for a little maid servant of brasss'\n",
      "Prediction: 'kit was arrested and the note of course was found on his person the evidence seemed so strong that the poor fellow was quickly tried found guilty and sentenced to prison for a long time all might have gone wrong but for a little maid servant of brasses'\n",
      "Example 6 (Speaker: 6233):\n",
      "Reference: 'poor mister poindexter will niver more see his son alive tis very mysterious remarked the major it is by jingo and the body too where can it be thats what purplexes me most of all'\n",
      "Prediction: 'poor mister poindexter will never more see his son alive tis very mysterious remarked the major it is by jingle and the body too where can it be thats what perplexes me most of all'\n",
      "Example 7 (Speaker: 114):\n",
      "Reference: 'and as the day had been uncommonly sultry and he had exerted himself a great deal it is no disparagement to the authors whoever they may have been to say that gradually and by slow degrees he fell asleep'\n",
      "Prediction: 'and as the day had been uncommonly sultry and he had exerted himself a great deal it is no disparagement to the authors whoever they may have been to say that gradually and by slow degrees he fell asleep'\n",
      "Example 8 (Speaker: 1649):\n",
      "Reference: 'that night as the youngsters were shouting and romping and skylarking as they always did before turning in he stood upon his cot and shouted silence list to me a little and then in the hush that followed'\n",
      "Prediction: 'that night as the youngsters were shouting and romping and sky larking as they always did before turning in he stood upon his cot and shouted silence list to me a little and then in the hush that followed'\n",
      "Example 9 (Speaker: 8138):\n",
      "Reference: 'i mean she answered that hed have been worth more to you than all the rest put together nell was a woman and her mind ran to the practical aspect of things look here peter she said youve been letting those dicks work you'\n",
      "Prediction: 'i mean she answered that hed have been worth more to you than all the rest put together nell was a woman and her mind ran to the practical aspect of things look here peter she said youve been letting those dicks work you'\n",
      "Example 10 (Speaker: 2882):\n",
      "Reference: 'her father as soon as he was out of sight slackened his pace and fell into that heavy listless step which told as well as words could do of hopelessness and weakness it was getting dark but he loitered on'\n",
      "Prediction: 'her father as soon as he was out of sight slackened his pace and fell into that heavy listless step which told as well as words could do of hopelessness and weakness it was getting dark but he loitered on'\n",
      "Example 11 (Speaker: 7095):\n",
      "Reference: 'generations followed and what had been offered as hypothetical theological suppositions were through custom and tradition taken for granted as unquestioned truth llewelyn powys'\n",
      "Prediction: 'generations followed and what had been offered as hypothetical theological suppositions were through custom and tradition taken for granted as unquestioned truth cluelin pawis'\n",
      "Example 12 (Speaker: 2751):\n",
      "Reference: 'it had been settled very definitely what mister poyser was to do when the young squire should appear and for the last five minutes he had been in a state of abstraction with his eyes fixed on the dark picture opposite'\n",
      "Prediction: 'it had been settled very definitely what mister poyser was to do when the young squire should appear and for the last five minutes he had been in a state of abstraction with his eyes fixed on the dark picture opposite'\n",
      "Example 13 (Speaker: 2473):\n",
      "Reference: 'mister romilly please wait for me she called after him i want to point out some of the buildings to you a dark young man wearing eyeglasses with a notebook and pencil in his hand swung around is this mister douglas romilly he enquired of the romilly shoe company'\n",
      "Prediction: 'mister romilly please wait for me she called after him i want to point out some of the buildings to you a dark young man wearing eyeglasses with a notebook and pencil in his hand swung around is this mister douglas romilly he inquired of the romilly shoe company'\n",
      "Example 14 (Speaker: 2581):\n",
      "Reference: 'he remembered and it seemed to him that he could meet that ghostly image which had risen from the black waters without shrinking almost contemptuously fate had mocked him long enough it was time indeed that he helped himself'\n",
      "Prediction: 'he remembered and it seemed to him that he could meet that ghostly image which had risen from the black waters without shrinking almost contemptuously fate had mocked him long enough it was time indeed that he helped himself'\n",
      "Example 15 (Speaker: 666):\n",
      "Reference: 'or elsewhere ever heard of willie price again and well might none hear the abandoned pitshaft does not deliver up its secret and so the bank of england'\n",
      "Prediction: 'or elsewhere ever heard of willie price again and well might none hear the abandoned pitshaft does not deliver up its secret and so the bank of england'\n",
      "\n",
      "Evaluation results saved to evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "vocab = \"abcdefghijklmnopqrstuvwxyz \"\n",
    "char_to_idx = {char: i+1 for i, char in enumerate(vocab)}\n",
    "idx_to_char = {i+1: char for i, char in enumerate(vocab)}\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "\n",
    "csv_file = \"/kaggle/working/mlpr-libri-kaggle.csv\"\n",
    "full_dataset = LibriASRDataset(csv_file)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    range(len(full_dataset)), \n",
    "    test_size=0.2, \n",
    "    random_state=42 \n",
    ")\n",
    "\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_idx, \n",
    "    test_size=0.25,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset, val_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "input_dim = 1024\n",
    "hidden_dim = 256\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "model = Model(input_dim=input_dim, hidden_dim=hidden_dim, vocab_size=vocab_size, num_layers=3, dropout_rate=0.3)\n",
    "\n",
    "best_val_loss = trainModel(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    char_to_idx, \n",
    "    num_epochs=30, \n",
    "    learning_rate=5e-4, \n",
    "    patience=5, \n",
    "    min_delta=0.01\n",
    ")\n",
    "\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"Evaluating best model on test set:\")\n",
    "test_loss, predictions, references = evaluateModel(model, test_loader, char_to_idx, idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf5f488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:07:09.262346Z",
     "iopub.status.busy": "2025-05-13T17:07:09.262009Z",
     "iopub.status.idle": "2025-05-13T17:07:09.332163Z",
     "shell.execute_reply": "2025-05-13T17:07:09.331267Z"
    },
    "papermill": {
     "duration": 0.39146,
     "end_time": "2025-05-13T17:07:09.333549",
     "exception": false,
     "start_time": "2025-05-13T17:07:08.942089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /kaggle/working/libri_asr_model.pt\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"/kaggle/working/libri_asr_model.pt\"\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab': vocab,\n",
    "    'char_to_idx': char_to_idx,\n",
    "    'idx_to_char': idx_to_char,\n",
    "    'model_config': {\n",
    "        'input_dim': input_dim,\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'vocab_size': vocab_size,\n",
    "        'num_layers': 3,\n",
    "        'dropout_rate': 0.3\n",
    "    }\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7358801,
     "sourceId": 11722511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7399993,
     "sourceId": 11785913,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7358015,
     "sourceId": 11786635,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7407901,
     "sourceId": 11796796,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7408136,
     "sourceId": 11797108,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7408345,
     "sourceId": 11797430,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9397.582324,
   "end_time": "2025-05-13T17:07:13.214933",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T14:30:35.632609",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
